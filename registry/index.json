{
  "schemaVersion": 2,
  "models": [
    {
      "name": "bge-small-en-v1.5",
      "owner": "BAAI",
      "type": "embedder",
      "description": "Compact and efficient English sentence embedding model. Great balance of speed and quality for semantic search applications.",
      "source": "BAAI/bge-small-en-v1.5",
      "size": 133987476,
      "variants": [
        "f16",
        "i8"
      ]
    },
    {
      "name": "all-MiniLM-L6-v2",
      "owner": "sentence-transformers",
      "type": "embedder",
      "description": "Extremely fast sentence embeddings model. Optimized for speed while maintaining good quality. Ideal for high-throughput applications.",
      "source": "sentence-transformers/all-MiniLM-L6-v2",
      "size": 91000000,
      "variants": [
        "f32",
        "f16",
        "i8"
      ],
      "backends": [
        "onnx"
      ]
    },
    {
      "name": "all-mpnet-base-v2",
      "owner": "sentence-transformers",
      "type": "embedder",
      "description": "High-quality sentence embeddings with excellent semantic understanding. Best accuracy among sentence-transformers models.",
      "source": "sentence-transformers/all-mpnet-base-v2",
      "size": 438000000,
      "variants": [
        "f32",
        "f16",
        "i8"
      ],
      "backends": [
        "onnx"
      ]
    },
    {
      "name": "clip-vit-base-patch32",
      "owner": "openai",
      "type": "embedder",
      "description": "Multimodal model that creates joint embeddings for both text and images. Enables cross-modal search and similarity. Requires ONNX Runtime.",
      "source": "openai/clip-vit-base-patch32",
      "size": 612032340,
      "variants": [
        "f16",
        "i8"
      ],
      "capabilities": [
        "multimodal"
      ],
      "backends": [
        "onnx"
      ]
    },
    {
      "name": "mxbai-rerank-base-v1",
      "owner": "mixedbread-ai",
      "type": "reranker",
      "description": "State-of-the-art document reranking model. Significantly improves search relevance by rescoring candidate documents.",
      "source": "mixedbread-ai/mxbai-rerank-base-v1",
      "size": 747254415,
      "variants": [
        "f16",
        "i8"
      ]
    },
    {
      "name": "chonky-mmbert-small-multilingual-1",
      "owner": "mirth",
      "type": "chunker",
      "description": "Neural semantic chunking model with multilingual support. Intelligently segments documents at natural semantic boundaries.",
      "source": "mirth/chonky_mmbert_small_multilingual_1",
      "size": 597479152,
      "variants": [
        "f16",
        "i8"
      ]
    },
    {
      "name": "rebel-large",
      "owner": "Babelscape",
      "type": "recognizer",
      "description": "Relation extraction model based on BART. Extracts entity-relation triplets from text for knowledge graph construction.",
      "source": "Babelscape/rebel-large",
      "size": 3163580492,
      "variants": [],
      "capabilities": [
        "relations"
      ]
    },
    {
      "name": "bert-base-NER",
      "owner": "dslim",
      "type": "recognizer",
      "description": "Standard BERT-based named entity recognition. Identifies Person, Organization, Location, and Miscellaneous entities.",
      "source": "dslim/bert-base-NER",
      "size": 433000000,
      "variants": [
        "f32",
        "f16",
        "i8"
      ],
      "capabilities": [
        "labels"
      ],
      "backends": [
        "onnx"
      ]
    },
    {
      "name": "bert-large-NER",
      "owner": "dslim",
      "type": "recognizer",
      "description": "Larger BERT model for named entity recognition. Higher accuracy than base model for complex entity extraction tasks.",
      "source": "dslim/bert-large-NER",
      "size": 1340000000,
      "variants": [
        "f32",
        "f16",
        "i8"
      ],
      "capabilities": [
        "labels"
      ],
      "backends": [
        "onnx"
      ]
    },
    {
      "name": "gliner_small-v2.1",
      "owner": "urchade",
      "type": "recognizer",
      "description": "Zero-shot NER model that can extract entities for any label without retraining. Specify custom entity types at inference time.",
      "source": "urchade/gliner_small-v2.1",
      "size": 209000000,
      "variants": [
        "f32",
        "f16",
        "i8"
      ],
      "capabilities": [
        "labels",
        "zeroshot"
      ],
      "backends": [
        "onnx"
      ]
    },
    {
      "name": "gliner-multitask-large-v0.5",
      "owner": "knowledgator",
      "type": "recognizer",
      "description": "Powerful multitask extraction model. Combines NER, zero-shot labeling, relation extraction, and question answering in one model.",
      "source": "knowledgator/gliner-multitask-large-v0.5",
      "size": 1420000000,
      "variants": [
        "f32",
        "f16",
        "i8"
      ],
      "capabilities": [
        "labels",
        "zeroshot",
        "relations",
        "answers"
      ],
      "backends": [
        "onnx"
      ]
    },
    {
      "name": "flan-t5-small-squad-qg",
      "owner": "lmqg",
      "type": "rewriter",
      "description": "Question generation model fine-tuned on SQuAD. Generates relevant questions from text passages for training data creation.",
      "source": "lmqg/flan-t5-small-squad-qg",
      "size": 596964700,
      "variants": []
    },
    {
      "name": "pegasus_paraphrase",
      "owner": "tuner007",
      "type": "rewriter",
      "description": "Paraphrasing model based on PEGASUS. Rewrites text while preserving meaning for data augmentation and style transfer.",
      "source": "tuner007/pegasus_paraphrase",
      "size": 4800242942,
      "variants": []
    },
    {
      "name": "functiongemma-270m-it",
      "owner": "google",
      "type": "generator",
      "description": "Compact instruction-tuned model optimized for function calling. Ideal for tool use and structured output generation.",
      "source": "google/functiongemma-270m-it",
      "size": 1174265658,
      "variants": []
    },
    {
      "name": "gemma-3-1b-it",
      "owner": "google",
      "type": "generator",
      "description": "Larger instruction-tuned Gemma model. Better reasoning and generation quality for more complex tasks.",
      "source": "google/gemma-3-1b-it",
      "size": 4000000000,
      "variants": []
    },
    {
      "name": "nomic-embed-text-v1.5",
      "owner": "nomic-ai",
      "type": "embedder",
      "description": "Long-context embeddings with Matryoshka support. Flexible dimensions (64-768) and 8K token context. Outperforms OpenAI text-embedding-3-small.",
      "source": "nomic-ai/nomic-embed-text-v1.5",
      "size": 548000000,
      "variants": [
        "f16",
        "i8"
      ],
      "backends": [
        "onnx"
      ]
    },
    {
      "name": "bge-m3",
      "owner": "BAAI",
      "type": "embedder",
      "description": "Multilingual embeddings supporting 100+ languages with 8K context. State-of-the-art for cross-lingual retrieval tasks.",
      "source": "BAAI/bge-m3",
      "size": 2270000000,
      "variants": [
        "f16",
        "i8"
      ],
      "backends": [
        "onnx"
      ]
    },
    {
      "name": "gte-Qwen2-1.5B-instruct",
      "owner": "Alibaba-NLP",
      "type": "embedder",
      "description": "Instruction-following embeddings with 32K context window. Best for long document retrieval and instruction-tuned tasks.",
      "source": "Alibaba-NLP/gte-Qwen2-1.5B-instruct",
      "size": 6000000000,
      "variants": [
        "f16"
      ],
      "backends": [
        "onnx"
      ]
    },
    {
      "name": "snowflake-arctic-embed-l-v2.0",
      "owner": "Snowflake",
      "type": "embedder",
      "description": "Retrieval-optimized embeddings with Matryoshka support. 1024 dimensions with excellent retrieval benchmarks.",
      "source": "Snowflake/snowflake-arctic-embed-l-v2.0",
      "size": 1340000000,
      "variants": [
        "f16",
        "i8"
      ],
      "backends": [
        "onnx"
      ]
    },
    {
      "name": "stella_en_1.5B_v5",
      "owner": "dunzhang",
      "type": "embedder",
      "description": "Premium English embeddings with Matryoshka support. Top-tier MTEB scores with excellent quality-to-size ratio.",
      "source": "dunzhang/stella_en_1.5B_v5",
      "size": 6000000000,
      "variants": [
        "f16"
      ],
      "backends": [
        "onnx"
      ]
    },
    {
      "name": "embeddinggemma-300m-ONNX",
      "owner": "onnx-community",
      "type": "embedder",
      "description": "Compact multilingual embeddings optimized for edge deployment. 100+ languages, 768 dims with Matryoshka support. Community ONNX export of Google's EmbeddingGemma.",
      "source": "onnx-community/embeddinggemma-300m-ONNX",
      "size": 1270000000,
      "variants": [
        "f16",
        "q4",
        "q4f16",
        "quantized"
      ],
      "backends": [
        "onnx"
      ]
    }
  ]
}